{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our training pictures\n",
    "train_dir_0 = os.path.join('train/zero')\n",
    "\n",
    "# Directory with our training pictures\n",
    "train_dir_1 = os.path.join('train/one')\n",
    "\n",
    "# Directory with our training pictures\n",
    "train_dir_2 = os.path.join('train/two')\n",
    "\n",
    "# Directory with our training pictures\n",
    "train_dir_3 = os.path.join('train/three')\n",
    "\n",
    "# Directory with our training pictures\n",
    "train_dir_4 = os.path.join('train/four')\n",
    "\n",
    "# Directory with our training pictures\n",
    "train_dir_5 = os.path.join('train/five')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_0 = os.listdir(train_dir_0)\n",
    "print(train_labels_0[:10])\n",
    "\n",
    "train_labels_1 = os.listdir(train_dir_1)\n",
    "print(train_labels_1[:10])\n",
    "\n",
    "train_labels_2 = os.listdir(train_dir_2)\n",
    "print(train_labels_2[:10])\n",
    "\n",
    "train_labels_3 = os.listdir(train_dir_3)\n",
    "print(train_labels_3[:10])\n",
    "\n",
    "train_labels_4 = os.listdir(train_dir_4)\n",
    "print(train_labels_4[:10])\n",
    "\n",
    "train_labels_5 = os.listdir(train_dir_5)\n",
    "print(train_labels_5[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training images:', len(os.listdir(train_dir_0)))\n",
    "print('total training images:', len(os.listdir(train_dir_1)))\n",
    "print('total training images:', len(os.listdir(train_dir_2)))\n",
    "print('total training images:', len(os.listdir(train_dir_3)))\n",
    "print('total training images:', len(os.listdir(train_dir_4)))\n",
    "print('total training images:', len(os.listdir(train_dir_5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for our graph\n",
    "nrows = 12\n",
    "ncols = 12\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_0_pix = [os.path.join(train_dir_0, fname) \n",
    "                for fname in train_labels_0[pic_index-8:pic_index]]\n",
    "next_1_pix = [os.path.join(train_dir_1, fname) \n",
    "                for fname in train_labels_1[pic_index-8:pic_index]]\n",
    "next_2_pix = [os.path.join(train_dir_2, fname) \n",
    "                for fname in train_labels_2[pic_index-8:pic_index]]\n",
    "next_3_pix = [os.path.join(train_dir_3, fname) \n",
    "                for fname in train_labels_3[pic_index-8:pic_index]]\n",
    "next_4_pix = [os.path.join(train_dir_4, fname) \n",
    "                for fname in train_labels_4[pic_index-8:pic_index]]\n",
    "next_5_pix = [os.path.join(train_dir_5, fname) \n",
    "                for fname in train_labels_5[pic_index-8:pic_index]]\n",
    "\n",
    "\n",
    "for i, img_path in enumerate(next_0_pix + next_1_pix + next_2_pix + next_3_pix + next_4_pix + next_5_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./ 255,\n",
    "    rotation_range = 30,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.4,\n",
    "    height_shift_range = 0.4,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1./ 255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train', # This is the source directory for training images\n",
    "        target_size = (300, 300),  # All images will be resized to 48x48\n",
    "        batch_size = 32, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "#Flow validation images in batches of 32 using train_datagen generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        'validation',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 48x48\n",
    "        batch_size=32, class_mode = 'categorical', color_mode = 'grayscale',\n",
    "        shuffle = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer = 'he_normal', input_shape = (300, 300, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer = 'he_normal', input_shape = (300, 300, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 4\n",
    "model.add(Conv2D(256, (3, 3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding = 'same', kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# Block 5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Block 6\n",
    "model.add(Dense(64, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block 7\n",
    "model.add(Dense(6, kernel_initializer = 'he_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('fingers.h5',\n",
    "                            monitor = 'val_loss',\n",
    "                            mode = 'min',\n",
    "                            save_best_only = True,\n",
    "                            verbose = 1\n",
    "                            )\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                         min_delta = 0,\n",
    "                         patience = 9,\n",
    "                         verbose = 1,\n",
    "                         restore_best_weights = True\n",
    "                         )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                             factor = 0.2,\n",
    "                             patience = 3,\n",
    "                             verbose = 1,\n",
    "                             min_delta = 0.0001\n",
    "                             )\n",
    "\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 2360\n",
    "validation_samples = 1196\n",
    "epochs = 25\n",
    "\n",
    "history = model.fit_generator(generator = train_generator,\n",
    "                                steps_per_epoch = train_samples // batch_size,\n",
    "                                epochs = epochs,\n",
    "                                callbacks = callbacks,\n",
    "                                validation_data = validation_generator,\n",
    "                                validation_steps = validation_samples // batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = cv2.imread('C:/Users/Dua/Desktop/finger_dataset/test/3.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img,(300,300))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes)\n",
    "if classes[0][0] == 1:\n",
    "    print(\"Predicted Zero(0)\")\n",
    "elif classes[0][1] == 1:\n",
    "    print(\"Predicted One(1)\")\n",
    "elif classes[0][2] == 1:\n",
    "    print(\"Predicted Two(2)\")\n",
    "elif classes[0][3] == 1:\n",
    "    print(\"Predicted Three(3)\")\n",
    "elif classes[0][4] == 1:\n",
    "    print(\"Predicted Four(4)\")\n",
    "else:\n",
    "    print(\"Predicted Five(5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img = cv2.imread('C:/Users/Dua/Desktop/3.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize(img,(300,300))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes)\n",
    "if classes[0][0] == 1:\n",
    "    print(\"Predicted Zero(0)\")\n",
    "elif classes[0][1] == 1:\n",
    "    print(\"Predicted One(1)\")\n",
    "elif classes[0][2] == 1:\n",
    "    print(\"Predicted Two(2)\")\n",
    "elif classes[0][3] == 1:\n",
    "    print(\"Predicted Three(3)\")\n",
    "elif classes[0][4] == 1:\n",
    "    print(\"Predicted Four(4)\")\n",
    "else:\n",
    "    print(\"Predicted Five(5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
